{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW0Ulk1GDDTv"
      },
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "<h1 align=\"center\">Tracing and Evaluating a LangChain Application</h1>\n",
        "\n",
        "LangChain provides high-level APIs that enable users to build powerful applications in a few lines of code. However, it can be challenging to understand what is going on under the hood and to pinpoint the cause of issues. Phoenix makes your LLM applications _observable_ by visualizing the underlying structure of each call to your query engine and surfacing problematic \"spans\" of execution based on latency, token count, or other evaluation metrics.\n",
        "\n",
        "In this tutorial, you will:\n",
        "\n",
        "- Build a simple question and answer app using LangChain that uses retrieval-augmented generation to answer questions over the Arize documentation,\n",
        "- Record trace data in OpenInference format,\n",
        "- Inspect the traces and spans of your application to identify sources of latency and cost,\n",
        "- Export your trace data as a pandas dataframe and run an LLM-assisted evaluation to measure the precision@k of your retrieval step.\n",
        "\n",
        "â„¹ï¸ This notebook requires an OpenAI API key.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV5Jwcx1DDTv"
      },
      "source": [
        "## 1. Install Dependencies and Import Libraries\n",
        "\n",
        "Install Phoenix, LangChain, and OpenAI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YIaoPAQ3DDTw",
        "outputId": "5febe08c-c24d-45cf-bf74-16c869c38e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain<=0.2.17\n",
            "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community<=0.2.19\n",
            "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-core<=0.2.43\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-openai<=0.1.25\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: openai>=1 in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Requirement already satisfied: httpx<0.28 in /usr/local/lib/python3.12/dist-packages (0.27.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: openinference-instrumentation-langchain in /usr/local/lib/python3.12/dist-packages (0.1.58)\n",
            "Requirement already satisfied: arize-phoenix[evals] in /usr/local/lib/python3.12/dist-packages (12.35.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain<=0.2.17) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain<=0.2.17) (2.0.46)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain<=0.2.17) (3.13.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<=0.2.17)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<=0.2.17)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2.0.0,>=1.26.0 (from langchain<=0.2.17)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain<=0.2.17) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain<=0.2.17) (2.32.5)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain<=0.2.17)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<=0.2.19) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<=0.2.43) (1.33)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<=0.2.43)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<=0.2.43) (4.15.0)\n",
            "Collecting openai>=1\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1) (4.67.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.28) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.28) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28) (0.16.0)\n",
            "Requirement already satisfied: aioitertools in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.13.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.22.1)\n",
            "Requirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.18.3)\n",
            "Requirement already satisfied: arize-phoenix-client>=1.28.1 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.28.1)\n",
            "Requirement already satisfied: arize-phoenix-evals>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (2.9.0)\n",
            "Requirement already satisfied: arize-phoenix-otel>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.14.0)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.6.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (7.0.0)\n",
            "Requirement already satisfied: email-validator in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (2.3.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.128.2)\n",
            "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.15.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.76.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (3.1.6)\n",
            "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.1.0)\n",
            "Requirement already satisfied: ldap3 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (2.9.1)\n",
            "Requirement already satisfied: openinference-instrumentation>=0.1.32 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.1.44)\n",
            "Requirement already satisfied: openinference-semantic-conventions>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.1.26)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.60b1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (3.11.7)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.24.1)\n",
            "Requirement already satisfied: protobuf>=4.25.8 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (5.29.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (2.9.0.post0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.0.22)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.16.3)\n",
            "Requirement already satisfied: sqlean-py>=3.45.1 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (3.50.4.5)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.50.0)\n",
            "Requirement already satisfied: strawberry-graphql==0.287.3 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.287.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (0.40.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.17.2 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix[evals]) (1.17.3)\n",
            "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql==0.287.3->arize-phoenix[evals]) (3.2.7)\n",
            "Requirement already satisfied: lia-web>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql==0.287.3->arize-phoenix[evals]) (0.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.12/dist-packages (from openinference-instrumentation-langchain) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.12/dist-packages (from openinference-instrumentation-langchain) (0.60b1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.2.17) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic<2,>=1.3.0->arize-phoenix[evals]) (1.3.10)\n",
            "Requirement already satisfied: jsonpath-ng in /usr/local/lib/python3.12/dist-packages (from arize-phoenix-evals>=2.8.0->arize-phoenix[evals]) (1.7.0)\n",
            "Requirement already satisfied: pystache in /usr/local/lib/python3.12/dist-packages (from arize-phoenix-evals>=2.8.0->arize-phoenix[evals]) (0.6.8)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<=0.2.19) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<=0.2.19) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<=0.2.43) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<=0.2.17) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->arize-phoenix[evals]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->arize-phoenix[evals]) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain<=0.2.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain<=0.2.17) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain<=0.2.17) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->arize-phoenix[evals]) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain<=0.2.17) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain<=0.2.17) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain<=0.2.17) (3.3.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib->arize-phoenix[evals]) (43.0.3)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator->arize-phoenix[evals]) (2.8.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi->arize-phoenix[evals]) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->arize-phoenix[evals]) (3.0.3)\n",
            "Requirement already satisfied: pyasn1>=0.4.6 in /usr/local/lib/python3.12/dist-packages (from ldap3->arize-phoenix[evals]) (0.6.2)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api->openinference-instrumentation-langchain) (8.7.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix[evals]) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix[evals]) (1.39.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp->arize-phoenix[evals]) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp->arize-phoenix[evals]) (1.39.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->arize-phoenix[evals]) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->arize-phoenix[evals]) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn->arize-phoenix[evals]) (8.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain) (3.23.0)\n",
            "Requirement already satisfied: cross-web>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from lia-web>=0.2.1->strawberry-graphql==0.287.3->arize-phoenix[evals]) (0.4.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<=0.2.19) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib->arize-phoenix[evals]) (2.0.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from jsonpath-ng->arize-phoenix-evals>=2.8.0->arize-phoenix[evals]) (3.11)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix[evals]) (3.0)\n",
            "Downloading langchain-0.2.17-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.19-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: tenacity, packaging, numpy, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.3\n",
            "    Uninstalling tenacity-9.1.3:\n",
            "      Successfully uninstalled tenacity-9.1.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 26.0\n",
            "    Uninstalling packaging-26.0:\n",
            "      Successfully uninstalled packaging-26.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.17.0\n",
            "    Uninstalling openai-2.17.0:\n",
            "      Successfully uninstalled openai-2.17.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.6.9\n",
            "    Uninstalling langsmith-0.6.9:\n",
            "      Successfully uninstalled langsmith-0.6.9\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.11\n",
            "    Uninstalling langchain-core-1.2.11:\n",
            "      Successfully uninstalled langchain-core-1.2.11\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 1.1.0\n",
            "    Uninstalling langchain-text-splitters-1.1.0:\n",
            "      Successfully uninstalled langchain-text-splitters-1.1.0\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 1.1.9\n",
            "    Uninstalling langchain-openai-1.1.9:\n",
            "      Successfully uninstalled langchain-openai-1.1.9\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.2.8\n",
            "    Uninstalling langchain-1.2.8:\n",
            "      Successfully uninstalled langchain-1.2.8\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.4.1\n",
            "    Uninstalling langchain-community-0.4.1:\n",
            "      Successfully uninstalled langchain-community-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-classic 1.0.1 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.2.43 which is incompatible.\n",
            "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.2.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.2.43 which is incompatible.\n",
            "google-adk 1.24.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-genai 1.62.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.2.17 langchain-community-0.2.19 langchain-core-0.2.43 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langsmith-0.1.147 numpy-1.26.4 openai-1.109.1 packaging-24.2 tenacity-8.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain",
                  "numpy",
                  "packaging"
                ]
              },
              "id": "0d9f8a28c9c54fbea177a76c477ba459"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"langchain<=0.2.17\" \"langchain-community<=0.2.19\" \"langchain-core<=0.2.43\"  \"langchain-openai<=0.1.25\" \"openai>=1\" 'httpx<0.28' \"arize-phoenix[evals]\" tiktoken nest-asyncio openinference-instrumentation-langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pc5_IALDDTw"
      },
      "source": [
        "Import libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tKHYn_jyDDTw",
        "outputId": "9593ed9a-3a7d-411f-c4c4-4df03c94d6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.chains'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1476529731.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetrievalQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrievers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNNRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.retrievers import KNNRetriever\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
        "from tqdm import tqdm\n",
        "\n",
        "import phoenix as px\n",
        "from phoenix.evals import (\n",
        "    HallucinationEvaluator,\n",
        "    OpenAIModel,\n",
        "    QAEvaluator,\n",
        "    RelevanceEvaluator,\n",
        "    run_evals,\n",
        ")\n",
        "from phoenix.otel import register\n",
        "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
        "from phoenix.trace import DocumentEvaluations\n",
        "\n",
        "nest_asyncio.apply()  # needed for concurrent evals in notebook environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCIs5fgwDDTw"
      },
      "source": [
        "## 2. Launch Phoenix\n",
        "\n",
        "You can run Phoenix in the background to collect trace data emitted by any LangChain application that has been instrumented with the `OpenInferenceTracer`.\n",
        "\n",
        "Launch Phoenix and follow the instructions in the cell output to open the Phoenix UI (the UI should be empty because we have yet to run a LangChain application).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGA33JwQDDTw"
      },
      "outputs": [],
      "source": [
        "(session := px.launch_app()).view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGXvM7eVDDTw"
      },
      "source": [
        "## 3. Configure Your OpenAI API Key\n",
        "\n",
        "Set your OpenAI API key if it is not already set as an environment variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NC88mpiDDTw"
      },
      "outputs": [],
      "source": [
        "if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
        "    openai_api_key = getpass(\"ğŸ”‘ Enter your OpenAI API key: \")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blse8wpUDDTx"
      },
      "source": [
        "### 4. Build Your LangChain Application\n",
        "\n",
        "This example uses a `RetrievalQA` chain over a pre-built index of the Arize documentation, but you can use whatever LangChain application you like.\n",
        "\n",
        "Download your pre-built index from cloud storage and instantiate your storage context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lrf-GTgDDTx"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\n",
        "    \"http://storage.googleapis.com/arize-phoenix-assets/datasets/\"\n",
        "    \"unstructured/llm/context-retrieval/langchain/database.parquet\"\n",
        ")\n",
        "knn_retriever = KNNRetriever(\n",
        "    index=np.stack(df[\"text_vector\"]),\n",
        "    texts=df[\"text\"].tolist(),\n",
        "    embeddings=OpenAIEmbeddings(),\n",
        ")\n",
        "chain_type = \"stuff\"  # stuff, refine, map_reduce, and map_rerank\n",
        "chat_model_name = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name=chat_model_name)\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=chain_type,\n",
        "    retriever=knn_retriever,\n",
        "    metadata={\"application_type\": \"question_answering\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lAfbXOVDDTx"
      },
      "source": [
        "Instrument LangChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwZVz2XTDDTx"
      },
      "outputs": [],
      "source": [
        "tracer_provider = register()\n",
        "LangChainInstrumentor(tracer_provider=tracer_provider).instrument(skip_dep_check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7uPVFSgDDTx"
      },
      "source": [
        "## 5. Run Your Query Engine and View Your Traces in Phoenix\n",
        "\n",
        "Download a sample of queries commonly asked of the Arize documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v55sFlFxDDTx"
      },
      "outputs": [],
      "source": [
        "url = \"http://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/context-retrieval/arize_docs_queries.jsonl\"\n",
        "queries = []\n",
        "with urlopen(url) as response:\n",
        "    for line in response:\n",
        "        line = line.decode(\"utf-8\").strip()\n",
        "        data = json.loads(line)\n",
        "        queries.append(data[\"query\"])\n",
        "queries[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4kpb2PiDDTx"
      },
      "source": [
        "Run a few queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HznOJzKfDDTx"
      },
      "outputs": [],
      "source": [
        "for query in tqdm(queries[:10]):\n",
        "    chain.invoke(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wps-NG1ODDTx"
      },
      "source": [
        "Check the Phoenix UI as your queries run. Your traces should appear in real time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es5k7OzlDDTx"
      },
      "source": [
        "## 6. Export and Evaluate Your Trace Data\n",
        "\n",
        "You can export your trace data as a pandas dataframe for further analysis and evaluation.\n",
        "\n",
        "In this case, we will export our `retriever` spans into two separate dataframes:\n",
        "\n",
        "- `queries_df`, in which the retrieved documents for each query are concatenated into a single column,\n",
        "- `retrieved_documents_df`, in which each retrieved document is \"exploded\" into its own row to enable the evaluation of each query-document pair in isolation.\n",
        "\n",
        "This will enable us to compute multiple kinds of evaluations, including:\n",
        "\n",
        "- relevance: Are the retrieved documents grounded in the response?\n",
        "- Q&A correctness: Are your application's responses grounded in the retrieved context?\n",
        "- hallucinations: Is your application making up false information?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Z2gMIlDDTx"
      },
      "outputs": [],
      "source": [
        "queries_df = get_qa_with_reference(px.Client())\n",
        "retrieved_documents_df = get_retrieved_documents(px.Client())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgj5DrKlDDTx"
      },
      "source": [
        "Next, define your evaluation model and your evaluators.\n",
        "\n",
        "Evaluators are built on top of language models and prompt the LLM to assess the quality of responses, the relevance of retrieved documents, etc., and provide a quality signal even in the absence of human-labeled data. Pick an evaluator type and instantiate it with the language model you want to use to perform evaluations using our battle-tested evaluation templates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgSk-GgVDDTx"
      },
      "outputs": [],
      "source": [
        "eval_model = OpenAIModel(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        ")\n",
        "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
        "qa_correctness_evaluator = QAEvaluator(eval_model)\n",
        "relevance_evaluator = RelevanceEvaluator(eval_model)\n",
        "\n",
        "hallucination_eval_df, qa_correctness_eval_df = run_evals(\n",
        "    dataframe=queries_df,\n",
        "    evaluators=[hallucination_evaluator, qa_correctness_evaluator],\n",
        "    provide_explanation=True,\n",
        ")\n",
        "relevance_eval_df = run_evals(\n",
        "    dataframe=retrieved_documents_df,\n",
        "    evaluators=[relevance_evaluator],\n",
        "    provide_explanation=True,\n",
        ")[0]\n",
        "\n",
        "from phoenix.client import AsyncClient\n",
        "\n",
        "px_client = AsyncClient()\n",
        "await px_client.spans.log_span_annotations_dataframe(\n",
        "    dataframe=hallucination_eval_df,\n",
        "    annotation_name=\"Hallucination\",\n",
        "    annotator_kind=\"LLM\",\n",
        ")\n",
        "await px_client.spans.log_span_annotations_dataframe(\n",
        "    dataframe=qa_correctness_eval_df,\n",
        "    annotation_name=\"QA Correctness\",\n",
        "    annotator_kind=\"LLM\",\n",
        ")\n",
        "\n",
        "px.Client().log_evaluations(\n",
        "    DocumentEvaluations(eval_name=\"Relevance\", dataframe=relevance_eval_df),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJEsjzV-DDTx"
      },
      "source": [
        "Your evaluations should now appear as annotations on the appropriate spans in Phoenix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBTlDTXDDDTx"
      },
      "outputs": [],
      "source": [
        "print(f\"ğŸš€ Open the Phoenix UI if you haven't already: {session.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bycpkzgXDDTx"
      },
      "source": [
        "## 7. Final Thoughts\n",
        "\n",
        "LLM Traces and the accompanying OpenInference Tracing specification is designed to be a category of telemetry data that is used to understand the execution of LLMs and the surrounding application context such as retrieval from vector stores and the usage of external tools such as search engines or APIs. It lets you understand the inner workings of the individual steps your application takes wile also giving you visibility into how your system is running and performing as a whole.\n",
        "\n",
        "LLM Evals are designed for simple, fast, and accurate LLM-based evaluations. They let you quickly benchmark the performance of your LLM application and help you identify the problematic spans of execution.\n",
        "\n",
        "For more details on Phoenix, LLM Tracing, and LLM Evals, checkout our [documentation](https://arize.com/docs/phoenix/).\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}